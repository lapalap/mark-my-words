{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset generation & collection of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "characters_CH = ['的', '一', '是', '不', '了', '在', '人', '有', '我', '他',\n",
    "            '这', '个', '们', '中', '来', '上', '大', '为', '和', '国']\n",
    "\n",
    "characters_lat = ['I','E','A','U','T','S','R','N','O','M','C','L','P',\n",
    "                  'D','B','Q','G','V','F','H']\n",
    "#https://www.sttmedia.com/characterfrequency-latin\n",
    "\n",
    "characters_hindi = ['ा','क','े','र','ह','स','न','ी','ं','म','ि','्','त',\n",
    "                    'प','ल','ो','य','ै','ब','द']\n",
    "#https://www.sttmedia.com/characterfrequency-hindi\n",
    "\n",
    "characters_numbers = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "\n",
    "# Note: To generate the datasets, fonts are required \n",
    "\n",
    "FONT_CH= ImageFont.truetype('../input/specialfonts/SongTi.ttf', 30)\n",
    "FONT_LAT= ImageFont.truetype('../input/specialfonts/times.ttf', 30)\n",
    "FONT_HINDI= ImageFont.truetype('../input/specialfonts/NirmalaB.ttf', 30)\n",
    "\n",
    "def add_watermark(img_path, save_path, font, characters):\n",
    "    image = Image.open(img_path)\n",
    "    msg = ''.join(np.random.choice(characters, 7))\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    w_img, h_img = image.size\n",
    "    w,h = font.getsize(msg)\n",
    "    \n",
    "    x, y = np.random.randint(0, w_img-w), np.random.randint(h, h_img-h)\n",
    "\n",
    "    draw.text((x,y), msg, font=font, fill=\"white\", anchor = 'ls')\n",
    "    image.save(save_path)\n",
    "    \n",
    "pairs = {'latin':[FONT_LAT, characters_lat],\n",
    "         'hindi':[FONT_HINDI, characters_hindi],\n",
    "         'arabic_numerals':[FONT_LAT,characters_numbers]\n",
    "        }\n",
    "\n",
    "for mode in pairs:\n",
    "    if not os.path.exists(mode):\n",
    "        os.makedirs(mode)\n",
    "    for path in tqdm(glob.glob('../dataset/baseline/*')):\n",
    "        name = path.split('/')[-1]\n",
    "        new_path = \"./{mode}/\".format(mode = mode) + name\n",
    "        add_watermark(path, new_path, pairs[mode][0], pairs[mode][1])\n",
    "\n",
    "!zip -r watermarks.zip  /kaggle/working/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Collecting the activations\n",
    "### Collecting the activations from the output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor(),\n",
    "                           torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                            std=[0.229, 0.224, 0.225])\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "import torchvision.models as models\n",
    "from timm import create_model\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    if model_name == 'resnet18':\n",
    "        return models.resnet18(pretrained=True).to(device)\n",
    "    if model_name == 'alexnet':\n",
    "        return models.alexnet(pretrained=True).to(device)\n",
    "    if model_name == 'vit_base_patch16_224':\n",
    "        return create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
    "    if model_name == 'beit_base_patch16_224':\n",
    "        return create_model('beit_base_patch16_224', pretrained=True).to(device)\n",
    "    if model_name == 'inception_v3':\n",
    "        return models.inception_v3(pretrained=True).to(device)\n",
    "    if model_name == 'densenet121':\n",
    "        return models.densenet121(pretrained=True).to(device)\n",
    "    if model_name == 'densenet201':\n",
    "        return models.densenet201(pretrained=True).to(device)\n",
    "    if model_name == 'densenet161':\n",
    "        return models.densenet161(pretrained=True).to(device)\n",
    "    if model_name == 'googlenet':\n",
    "        return models.googlenet(pretrained=True).to(device)\n",
    "    if model_name == 'vgg11':\n",
    "        return models.vgg11(pretrained=True).to(device)\n",
    "    if model_name == 'vgg13':\n",
    "        return models.vgg13(pretrained=True).to(device)\n",
    "    if model_name == 'vgg16':\n",
    "        return models.vgg16(pretrained=True).to(device)\n",
    "    if model_name == 'vgg19':\n",
    "        return models.vgg19(pretrained=True).to(device)\n",
    "    if model_name == 'mobilenet_v2':\n",
    "        return models.mobilenet_v2(pretrained=True).to(device)\n",
    "    if model_name == 'shufflenet_v2_x1_0':\n",
    "        return models.shufflenet_v2_x1_0(pretrained=True).to(device)\n",
    "    if model_name == 'resnet50':\n",
    "        return models.resnet50(pretrained=True).to(device)\n",
    "    if model_name == 'resnet101':\n",
    "        return models.resnet50(pretrained=True).to(device)\n",
    "    if model_name == 'resnet152':\n",
    "        return models.resnet152(pretrained=True).to(device)\n",
    "    if model_name == 'resnext101_32x8d':\n",
    "        return models.resnext101_32x8d(pretrained=True).to(device)\n",
    "    if model_name == 'wide_resnet101_2':\n",
    "        return models.wide_resnet101_2(pretrained=True).to(device)\n",
    "\n",
    "model_names = ['resnet18',\n",
    "               'resnet50',\n",
    "               'resnet101',\n",
    "               'resnet152',\n",
    "               'resnext101_32x8d',\n",
    "               'wide_resnet101_2',\n",
    "               'alexnet',\n",
    "               'vit_base_patch16_224',\n",
    "               'beit_base_patch16_224',\n",
    "               'inception_v3',\n",
    "               'densenet161',\n",
    "               'mobilenet_v2',\n",
    "               'shufflenet_v2_x1_0',\n",
    "               'densenet121',\n",
    "               'densenet201',\n",
    "               'googlenet',\n",
    "               'vgg11',\n",
    "               'vgg13',\n",
    "               'vgg16',\n",
    "               'vgg19'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import cv2\n",
    "\n",
    "class_names = ['baseline',\n",
    "               'chinese',\n",
    "               'latin',\n",
    "               'hindi',\n",
    "               'arabic_numerals'\n",
    "              ]\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,root,transform):\n",
    "        self.root=root\n",
    "        self.transform=transform\n",
    "\n",
    "        self.image_names=glob.glob(self.root + '*.JPEG')\n",
    "        self.image_names.sort()\n",
    "   \n",
    "    #The __len__ function returns the number of samples in our dataset.\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    " \n",
    "    def __getitem__(self,index):\n",
    "        image=cv2.imread(self.image_names[index])\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image=self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for j, model_name in enumerate(model_names):\n",
    "        model = get_model(model_name)\n",
    "        model.eval()\n",
    "\n",
    "        logit_scores = torch.zeros([998, 5, 1000])\n",
    "\n",
    "        for c, class_name in enumerate(class_names):\n",
    "            dataset = ImageDataset('../dataset/{class_name}/'.format(class_name = class_name),\n",
    "                                   transforms\n",
    "                                  )\n",
    "            testloader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=512,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)\n",
    "            counter = 0\n",
    "            with torch.no_grad():\n",
    "                for i, x in tqdm(enumerate(testloader)):\n",
    "                    x = x.float().data.to(device)\n",
    "\n",
    "                    outputs = model(x)\n",
    "                    logit_scores[counter:counter + x.shape[0],c,:] = outputs\n",
    "\n",
    "                    counter += x.shape[0]\n",
    "\n",
    "        torch.save(logit_scores, '../activations/{name}_wtrmrks.tnsr'.format(name = model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the activations from the feature extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_features_names = ['resnet18',\n",
    "                        'alexnet',\n",
    "                        'googlenet',\n",
    "                        'vit_base_patch16_224',\n",
    "                        'beit_base_patch16_224',\n",
    "                        'inception_v3',\n",
    "                        'densenet161',\n",
    "                        'mobilenet_v2',\n",
    "                        'shufflenet_v2_x1_0',\n",
    "                        'vgg11']\n",
    "\n",
    "activation = {}\n",
    "\n",
    "def make_hooks(model_name):\n",
    "    if model_name == 'resnet18': #512\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.mean(axis = [2,3])\n",
    "            return hook\n",
    "        model.avgpool.register_forward_hook(get_activation('features'))\n",
    "        return 512\n",
    "    elif model_name == 'alexnet': #4096\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output\n",
    "            return hook\n",
    "        model.classifier[5].register_forward_hook(get_activation('features'))\n",
    "        return 4096\n",
    "    elif model_name == 'vit_base_patch16_224': #768\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output\n",
    "            return hook\n",
    "        model.fc_norm.register_forward_hook(get_activation('features'))\n",
    "        return 768\n",
    "    elif model_name == 'beit_base_patch16_224':\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output\n",
    "            return hook\n",
    "        model.fc_norm.register_forward_hook(get_activation('features'))\n",
    "        return 768\n",
    "    elif model_name == 'inception_v3':\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.mean(axis = [2,3])\n",
    "            return hook\n",
    "        model.avgpool.register_forward_hook(get_activation('features'))\n",
    "        return 2048\n",
    "    elif model_name == 'densenet161':\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.mean(axis = [2,3])\n",
    "            return hook\n",
    "        model.features.register_forward_hook(get_activation('features'))\n",
    "        return 2208\n",
    "    elif model_name == 'mobilenet_v2':\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.mean(axis = [2,3])\n",
    "            return hook\n",
    "        model.features.register_forward_hook(get_activation('features'))\n",
    "        return 1280\n",
    "    elif model_name == 'shufflenet_v2_x1_0':\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.mean(axis = [2,3])\n",
    "            return hook\n",
    "        model.conv5.register_forward_hook(get_activation('features'))\n",
    "        return 1024\n",
    "    elif model_name == 'vgg11':\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output\n",
    "            return hook\n",
    "        model.classifier[5].register_forward_hook(get_activation('features'))\n",
    "        return 4096\n",
    "    elif model_name == 'googlenet':\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output\n",
    "            return hook\n",
    "        model.dropout.register_forward_hook(get_activation('features'))\n",
    "        return 1024\n",
    "        \n",
    "with torch.no_grad():\n",
    "    for j, model_name in enumerate(model_features_names):\n",
    "        model = get_model(model_name)\n",
    "        d = make_hooks(model_name)\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        logit_scores = torch.zeros([998, 5, d])\n",
    "        \n",
    "        for c, class_name in enumerate(class_names):\n",
    "            dataset = ImageDataset('../dataset/{class_name}/'.format(class_name = class_name),\n",
    "                                   transforms\n",
    "                                  )\n",
    "            testloader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=512,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)\n",
    "            \n",
    "            counter = 0\n",
    "            with torch.no_grad():\n",
    "                for i, x in tqdm(enumerate(testloader)):\n",
    "                    x = x.float().data.to(device)\n",
    "\n",
    "                    outputs = model(x)\n",
    "                    logit_scores[counter:counter + x.shape[0],c,:] = activation[\"features\"]\n",
    "\n",
    "                    counter += x.shape[0]\n",
    "            \n",
    "        torch.save(logit_scores, '../activations/{name}_features_wtrmrks.tnsr'.format(name = model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
